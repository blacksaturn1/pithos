
version: '3'

services:
  deep_notebook:
    image: jupyter/tensorflow-notebook   
    volumes:
      - ./airflow/dags/:/airflow/dags/
    tty: true
    privileged: true
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_HOME=/spark
      - ENABLE_INIT_DAEMON='false'
    command:  start.sh jupyter lab --LabApp.token='' --NotebookApp.notebook_dir=/airflow/dags/
    ports:
      - 8080:8888


  postgres_airflow:
    image: postgres:9.5
    restart: always
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    ports:
      - 5432:5432

   postgres_superset:
    image: postgres
    restart: always
    environment:
      POSTGRES_DB: superset
      POSTGRES_PASSWORD: superset
      POSTGRES_USER: superset
    volumes:
      - ./superset/postgres/data:/var/lib/postgresql/data



  redis:
    image: 'redis:3.2.7'
    container_name: redis_pithos
    restart: always
    volumes:
      - redis:/data

  airflow:
     image: puckel/docker-airflow:1.9.0-2
     restart: always
     depends_on:
         - postgres_airflow
     environment:
         - LOAD_EX=n
         - EXECUTOR=Local
         - FERNET_KEY=my-local-fernet-key
     volumes:
         - ./airflow/dags:/usr/local/airflow/dags
         # custom plugins
         - ./airflow/plugins:/usr/local/airflow/plugins
     ports:
         - "8081:8080"
     command: webserver

  superset:
    image: amancevice/superset
    depends_on:
      - redis
      - postgres_superset
    container_name: devtrac_superset
    environment:
      MAPBOX_API_KEY: ${MAPBOX_API_KEY}
    volumes:
      - ./superset/superset_config.py:/etc/superset/superset_config.py
    ports:
      - "8088:8088"
    
networks:
  hadoop:
    external: true
volumes:
  redis:
    external: true
